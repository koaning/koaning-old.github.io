Advanced R 
========================================================

This document describes some lessons I would like to teach on the advanced subjects of R. We will need the following packages. 

```{r}
library(microbenchmark)
library(dplyr)
library(ggplot2)
library(randomForest)
```

## R Vocabulary 

R is full of functions. Many of them are very useful albeit infrequently used and unknown. Here I have a list of such functions. 

```
?
rm
```

## Style 

### The damn assignment operator 

R can sometimes feel a little silly when you are used to a different programming language. Example, the following assignments are valid: 

```{r}
x = 2 
x <- 2 
2 -> x 
```

There is some debate on which is better. A lot of confusion arises from this. 

```{r}
add = function(a,b){
  return(a + b)
}

add(a=3, b=2)
a
b

add(x1<-1, x2<-2)
a
b

add(a<-1, b<-2)
a
b

rm(a)
rm(b) 
```

I prefer to use ```=``` for consistency with other programming language. Feel free to use whatever you prefer, but be consistent in your choice. 

## Functional Programming 

#### Many ways to write a function 
In R there are many ways to write the same function. 

```{r}
add = function(a,b){
  return(a + b)
}

add = function(a,b){
  a + b 
}

add = function(a,b) a + b 
```

These three functions do exactly the same thing. A few things to note: 
- a function does not need a ```return``` statement to return a value, if no return statement is given it will return the final value on the body of the function 
- a function does not need curly brackets if you are only running one line of code. 
- you can immediately see that we could use a style guide when working together in a group. 

We can take this a step further by also adding ```if``` statements in our code. 

```{r}
posneg = function(a){
  if (a<0) return('neg')
  else if(a>0) return('pos')
  else '0'
}

posneg = function(a){
  if (a<0) 'neg'
  else if (a>0) 'pos'
  else '0'
}

posneg = function(a){
  if (a<0) return('neg')
  if (a>0) return('pos')
  '0'
}
```

Usually, it is preferable that you use as little characters as possible, as long as the code remains clear to your collegues. For larger codebases I can actually recommend that you use backets ```{}```.

#### Functions as input

In R you can write functions that accept functions as input as well as functions that return other functions. Suppose that I wanted to write a function that can either add or multiply two numbers. 

A possible way would be to do the following: 

```{r}
runfunc = function(a,b,f){
  if (f == "add"){
    return(a+b)
  }else{
    return(a*b)
  }
}
```

There are a few things that aren't nice about this setup. 
- if ```f="foobar"``` we might want the function to give an error instead of ```a+b```
- if we need to add another function to the possible list of functions that ```runfunc``` can run we need to add another ```if else```, which means a lot of lines of extra code 

A possible improvement might be: 

```{r}
add = function(a,b) a + b 
mult = function(a,b) a * b 

runfunc = function(a,b,f){
  return f(a,b)
}
```

#### Functions as Output, Clojures

A more powerful example of what I have just shown : 

```{r}
power = function(exponent) {
  function(x) x ^ exponent
}

square = power(2)
square(2) # -> [1] 4
square(4) # -> [1] 16

cube = power(3)
cube(2) # -> [1] 8
cube(4) # -> [1] 64

power(4)(3)
```

#### ```<<-``` vs ```<-``` 

It's all about scope. 

```{r}
counter = function() {
  i <- 0
  function() {
    i <<- i + 1
    i
  }
}

c1 = counter() 
c2 = counter() 

bad_counter = function(){
  i = 0
  function() {
    i = i + 1
    i
  }
}

c3 = bad_counter()
c1()
c1()
c1()
c2()
c2()
c3()
c3()
```

##### Recursion 

Recursion is the most extreme version of a function calling another function. 

> To understand recursion, you need to understand recursion.

```{r}
fib = function(len){
  if (len == 1) return(1)
  if (len == 2) return(1)
  return(fib2(len-1) + fib2(len-2))
}
```

### Applications 

#### Numerical Integration 

```{r}

```
## ggplot2 & reshape2 

```{r results='hide', message=FALSE, warning=FALSE} 
library(ggplot2)
library(reshape2)
```

lazy evaluation of ggplot 
show the reshape2 tools 

## apply, sapply, lapply

```{r results='hide', message=FALSE, warning=FALSE}
library(dplyr)
```

## dplyr & chaining

```{r}
df = ChickWeight

```

## Performance 

We should never optimize before we know what is inperformant. You can check the performance of some of your code via the ```microbenchmark``` library. 

```{r}
library(microbenchmark)
```

An alternative method for profiling is to use the ```system.time``` method, but this is much less accurate. 

```{r}
x <- runif(1000)
microbenchmark(
  sqrt(x),
  x ^ (1 / 2),
  exp(log(x) / 2)
)
```

There are three ways to calculate a square root and we notice that one function is significantly quicker than the others. Another benchmark is to look at the number of evaluations that are needed instead of looking at the time it takes to execute. 

```{r}
x <- runif(1000)
microbenchmark(
  sqrt(x),
  x ^ (1 / 2),
  exp(log(x) / 2), 
  unit = "eps"
)
```

In this case, higher means better. We can also compare two implementations of the ```fib``` function. 

Possible exercizes:

1. Compare the arithmetic operators ( ```+```, ```-```, ```*```, ```/```, ```^```) on performance and visualise the results. 
2. Think before you check. Which of the following functions for the fibonachi sequence would run quicker? 

```{r}
fib1 = function(len){
  fibvals = numeric(len)
  fibvals[1] = 1
  fibvals[2] = 1
  for (i in 3:len) { 
     fibvals[i] <- fibvals[i-1]+fibvals[i-2]
  }
  fibvals[len]
}

fib2 = function(len){
  if(len == 1) return(1)
  if(len == 2) return(1)
  return(fib2(len-1) + fib2(len-2))
}
```

## Performance 2

Below I will show you multiple ways to select a subset of data in a dataframe. 

```{r}
microbenchmark(
  "[32, 11]"      = mtcars[32, 11],
  "$carb[32]"     = mtcars$carb[32],
  "[[c(11, 32)]]" = mtcars[[c(11, 32)]],
  "[[11]][32]"    = mtcars[[11]][32],
  ".subset2"      = .subset2(mtcars, 11)[32],
  "dplyr 1"       = mtcars %>% select(11) %>% slice(32),
  "dplyr 2"       = select(mtcars, 11) %>% slice(32),
  "dplyr 3"       = slice(select(mtcars, 11),32)
)
```

Notice the performance difference. The reason of the difference? Nobody has fixed the improvements. Selecting maximum/minimum values also can be done a lot quicker if you pick different functions. 

R does some opertions in verctorized mode. If it knows all types in an array to be of a certain type you shouldn't always write an ```apply``` type function for it. 

```{r}
x = runif(1000)
microbenchmark(
  sapply(x, function(x){ x * 2}),
  x * 2
)
```

## Performance 3 

Let's have a look at the ```dplyr``` package. The performance is impressive. Also notice that the syntax is much more elegant. 

```{r}
microbenchmark(
  "dyplr" = filter(ChickWeight, Diet == 1),
  "dfindex" = ChickWeight[ChickWeight$Diet==1,],
  "subset" = subset(ChickWeight, ChickWeight$Diet == 1)
)
```

Also for aggregations it seems to be very performant. 

```{r}
microbenchmark(
  "dplyr" = summarise(group_by(ChickWeight, Diet, Time), mean(weight)),
  "aggregate" = aggregate(data=ChickWeight, weight ~ Time + Diet, FUN=mean)
)
```

Guess we should start switching over to ```dplyr``` very soon. 


### Profiling 

```{r}
library(devtools)
devtools::install_github("hadley/lineprof")
library(lineprof)

f <- function() {
  pause(0.1)
  g()
  h()
}
g <- function() {
  pause(0.1)
  h()
}
h <- function() {
  pause(0.1)
}

l <- lineprof(f())
l
```

## Parallel Code 

```{r}
library(parallel)

cores <- detectCores()
cores
#> [1] 32

pause <- function(i) {
  function(x) Sys.sleep(i)
}

system.time(lapply(1:10, pause(0.25)))
system.time(mclapply(1:10, pause(0.25), mc.cores = cores))
```

### Elegant way to simulate data 

## Map Plotting 

Google Maps in R
========================================================

The ```ggmap`` package can be used to plot over google tiles. It also comes with some nice tools to geocode information. 

```{r}
library(ggmap)
geocode("amsterdam")$lon + rnorm(10)/100
geocode("amsterdam")$lon + rnorm(10)/100
```

You can also embed plots, for example:

```{r fig.width=7, fig.height=6}
df = data.frame(
  lon=geocode("amsterdam")$lon + rnorm(100)/100,
  lat=geocode("amsterdam")$lat + rnorm(100)/100,
  foobar = ifelse(runif(100)<0.5,"yes","no")
)

qmap("amsterdam", zoom=13) + geom_point(data=df, aes(lon,lat))
qmap("amsterdam", zoom=14, source = "stamen", maptype = "toner") + geom_point(data=df, aes(lon,lat, colour=foobar)) + facet_grid( foobar ~ .)
```

## Automation 

#### A list of formulas, applied to lm 

You need to think more and more like an engineer as a data scientist. 

```{r}
formulas = c(
  as.formula("weight ~ Time"),
  as.formula("weight ~ Time + Diet"),
  as.formula("weight ~ Diet")
)

for(form in formulas){
  print("form")
  print(lm(formula=form, data=ChickWeight))
}
```

#### Different methods 

```{r}
formulas = c(
  as.formula("weight ~ Time"),
  as.formula("weight ~ Time + Diet"),
  as.formula("weight ~ Diet")
)

methods = list(lm, randomForest)
names(methods) = c('regression', 'forest')

mse = function(arr1, arr2){
  sum((arr1-arr2)^2)
}

lowest = 99^99
for(method in methods){
  for(form in formulas){
    model = method(formula=form, data=ChickWeight)
    currmse = mse(select(ChickWeight, weight), predict(model, ChickWeight));
  }
}
```

## Data Science 

#### ```dplyr``` basic syntax 

#### ```ggplot2``` basic syntax 

#### ```caret``` basics 

```{r}
library(mlbench)
library(caret)
library(randomForest)
set.seed(123)
data(Sonar)
str(Sonar[, 1:10])
inTraining = createDataPartition(Sonar$Class, p = 0.75, list = FALSE)
training = Sonar[inTraining, ]
testing = Sonar[-inTraining, ]
```

We have now split the Sonar dataset in the training and test set. 

```{r}
# http://topepo.github.io/caret/modelList.html
tuning_params = expand.grid(size = 1:12, decay=0)

fitControl = trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 4,
                           ## repeated ten times
                           repeats = 10)

fit = train(Class ~ ., data = training,
                 method = "nnet",
                 trControl = fitControl,
                 verbose = FALSE,
                 tuneGrid = tuning_params)
fit
varImp(fit)
plot(fit)
```

#### basic parallel pattern in R

```{r}
library(parallel)
library(MASS)
library(microbenchmark)

test <- lapply(1:100,function(x) rnorm(10000))

df = data.frame(cores=as.numeric(), time=as.numeric())

for( i in 1:10 ){
  print(i)
  t = system.time(x <- lapply(test,function(x) loess.smooth(x,x)))
  df = rbind(df, data.frame(cores=as.numeric(0), time=t[[3]]))
}

for (i1 in 1:10){
  for (i2 in 1:5){
    print(c(i1,i2))
    t = system.time(x <- mclapply(test,function(x) loess.smooth(x,x), mc.cores=i1))
    df = rbind(df, data.frame(cores=as.numeric(i1), time=t[[3]]))
  }
}

av = df %>% filter(cores == 0) %>% summarise(mean = mean(time))
p = ggplot() + geom_point(data=df, aes(cores, time)) 
p + ggtitle("Higher performance when cores are added (8-core machine)")

p = p + geom_line(aes(x = seq(1,10,0.01), y = av[[1]]/seq(1,10,0.01)), colour="red") 
p + ggtitle("Higher performance when cores are added (8-core machine)")
```

You can detect the number of maximum cores via:

```{r}
options(mc.cores = detectCores())
```


#### bootstrapping 

Sometimes the dataset is too big because you have a CPU bound. R is uaully single threaded. Possible solution: bootstrapping. 
This combines well with the multicore approach. 


#### Building your own Regressor

Simulation is simple. 

```{r}
len = 40
x1 = sapply(1:len, sin)
b0 = 3.5
b1 = 2.3
y = b0 + b1 * x1 + rnorm(40)
df = data.frame(y=y, x0=1, x1=x1)
```

We can create an error function. 

```{r}
error = function(df, b0, b2){
   sum((y - b0*df$x0 - b1*df$x1)^2)
}

edf = data.frame(b0 = as.numeric(), b1 = as.numeric(), e = as.numeric())
for( b0 in seq(0,5,0.1) ){
  for( b1 in seq(0,5,0.1) ){
    newline = data.frame(b0=b0, b1=b1, e=error(df, b0, b1))
    edf = rbind(edf, newline)
  }
}
```

Via looping we get the best value for beta. 

```{r}
ggplot() + geom_point(data=filter(edf, b0 == 1), aes(x=b1, y=e))
ggplot() + geom_point(data=filter(edf, b1 == 1), aes(x=b0, y=e))
ggplot() + geom_tile(data=edf, aes(x=b1, y=b2, fill=e), colour='white')
ggplot() + geom_tile(data=edf, aes(x=b1, y=b2, fill=e<60), colour='white')
```

Time to refactor some things. 

```{r}
generate = function(len=40, b0=2.5, b1=2.5){
  len = 40
  x1 = sapply(1:len, sin)
  b0 = 3.5
  b1 = 2.3
  y = b0 + b1 * x1 + rnorm(40)
  return(data.frame(y=y, x0=1, x1=x1))
}

error = function(df, b1, b2){
   sum((df$y - b1*df$x1 - b2*df$x2)^2)
}

make_seq = function(x, stepsize){
  seq(x - stepsize * 10, x + stepsize * 10, stepsize)
}

errordf = function(df, b1, b2, stepsize){
  edf = data.frame(b1 = as.numeric(), b2 = as.numeric(), e = as.numeric())
  for( b1_i in make_seq(b1, stepsize) ){
	  for( b2_i in make_seq(b1, stepsize) ){
	    newline = data.frame(b1 = b1_i, b2 = b2_i, e = error(df, b1_i, b2_i))
	    edf = rbind(edf, newline)
	  }
	}
  edf
}
  
findfit = function(df, b1, b2, stepsize){
  if (stepsize < 0.001 ) return(c(b1,b2))
  edf = errordf(df, b1, b2, stepsize)
  # print(select(edf) %>% filter(e == min(edf$e)) %>% select(e))
  min_b1 = select(edf) %>% filter(e == min(edf$e)) %>% select(b1) %>% as.numeric
  min_b2 = select(edf) %>% filter(e == min(edf$e)) %>% select(b2) %>% as.numeric
  return(findfit(df, min_b1, min_b2, stepsize/2))
}

df = generate(100)
findfit(df, 3, 3, 1)
lm('y ~ x1 + x2', df)
```

Compare our output with the standard linear regressor. 

## Variable Selection Basics

Explain the problem. 

Explain the caret package.

## Ensembles 

```{r}

```

# Concluding Tips 

## dealing with large files 

##### ```read.table```

```{r}
read.table('/Users/code/Downloads/0001.csv', nrows=50, sep = ',')
```

##### ```data.tables```

```{r}
library(data.table)
df = fread('/Users/code/Downloads/train', select = c('colname1', 'colname2'), colClasses = c('character', 'integer'), sep = ',')
```

##### ```sqldf```

```{r}
library(sqldf)
sqldf('select weight from ChickWeight')
read.csv.sql('/Users/code/Downloads/0001.csv', 'select * from file limit 10')
```

# Visualisation 

Google Maps in R
========================================================

```{r}
library(ggmap)
geocode("amsterdam")$lon + rnorm(10)/100
geocode("amsterdam")$lon + rnorm(10)/100
```

You can also embed plots, for example:

```{r fig.width=7, fig.height=6}
df = data.frame(
  lon=geocode("amsterdam")$lon + rnorm(100)/100,
  lat=geocode("amsterdam")$lat + rnorm(100)/100,
  foobar = ifelse(runif(100)<0.5,"yes","no")
)

qmap("amsterdam", zoom=13) + geom_point(data=df, aes(lon,lat))
qmap("amsterdam", zoom=14, source = "stamen", maptype = "toner") + geom_point(data=df, aes(lon,lat, colour=foobar)) + facet_grid( foobar ~ .)
```

